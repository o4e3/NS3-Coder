{
  "repo_name": "joyhsu0504/NS3D",
  "github_url": "https://github.com/joyhsu0504/NS3D",
  "readme": "# NS3D: Neuro-Symbolic Grounding of 3D Objects and Relations\n\n\n![figure](figure.png)\n<br />\n<br />\n**[NS3D: Neuro-Symbolic Grounding of 3D Objects and Relations](https://arxiv.org/abs/2303.13483)**\n<br />\n[Joy Hsu](http://web.stanford.edu/~joycj/),\n[Jiayuan Mao](http://jiayuanm.com/),\n[Jiajun Wu](https://jiajunwu.com/)\n<br />\nIn Conference on Computer Vision and Pattern Recognition (CVPR) 2023\n<br />\n\n## Dataset\nOur dataset download process follows the [ReferIt3D benchmark](https://github.com/referit3d/referit3d).\n\nSpecifically, you will need to\n- (1) Download `sr3d_train.csv` and `sr3d_test.csv` from this [link](https://drive.google.com/drive/folders/1DS4uQq7fCmbJHeE-rEbO8G1-XatGEqNV)\n- (2) Download scans from ScanNet and process them according to this [link](https://github.com/referit3d/referit3d/blob/eccv/referit3d/data/scannet/README.md). This should result in a `keep_all_points_with_global_scan_alignment.pkl` file.\n\n## Setup\n\nRun the following commands to install necessary dependencies.\n\n```bash\n  conda create -n ns3d python=3.7.11\n  conda activate ns3d\n  pip install -r requirements.txt\n```\n\nInstall [Jacinle](https://github.com/vacancy/Jacinle).\n```bash\n  git clone https://github.com/vacancy/Jacinle --recursive\n  export PATH=<path_to_jacinle>/bin:$PATH\n```\n\nInstall the referit3d python package from [ReferIt3D](https://github.com/referit3d/referit3d).\n```bash\n  git clone https://github.com/referit3d/referit3d\n  cd referit3d\n  pip install -e .\n```\n\nCompile CUDA layers for [PointNet++](http://arxiv.org/abs/1706.02413).\n```bash\n  cd models/scene_graph/point_net_pp/pointnet2\n  python setup.py install\n```\n\n\n## Evaluation\n\nTo evaluate NS3D:\n\n```bash\n\n  scannet=<path_to/keep_all_points_with_global_scan_alignment.pkl>\n  referit=<path_to/sr3d_train.csv>\n  load_path=<path_to/model_to_evaluate.pth>\n  \n  jac-run ns3d/trainval.py --desc ns3d/desc_ns3d.py --scannet-file $scannet --referit3D-file $referit --load $load_path --evaluate\n```\n\nWeights for our trained NS3D model can be found at [trained_ns3d.pth](https://drive.google.com/drive/folders/1NKFcxqb9OnfqZBgSSTLBiChntSl7svbs?usp=sharing) and loaded into `load_path`.\n\n\n\n## Training\n\nTo train NS3D:\n\n```bash\n\n  scannet=<path_to/keep_all_points_with_global_scan_alignment.pkl>\n  referit=<path_to/sr3d_train.csv>\n  load_path=<path_to/pretrained_classification_model.pth>\n  \n  jac-run ns3d/trainval.py --desc ns3d/desc_ns3d.py --scannet-file $scannet --referit3D-file $referit --load $load_path --lr 0.0001 --epochs 5000 --save-interval 1 --validation-interval 1\n```\n\nWeights for our pretrained classification model can be found at [pretrained_cls.pth](https://drive.google.com/drive/folders/1NKFcxqb9OnfqZBgSSTLBiChntSl7svbs?usp=sharing) and loaded into `load_path`.\n\n\n\n## Acknowledgements\n\nOur codebase is built on top of [NSCL](https://github.com/vacancy/NSCL-PyTorch-Release) and [ReferIt3D](https://github.com/referit3d/referit3d). Please feel free to email me at joycj@stanford.edu if any problems arise.\n",
  "examples": []
}