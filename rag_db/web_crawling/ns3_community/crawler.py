from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import tempfile
import shutil
import time
import json
import re

# 1. Chrome ì˜µì…˜ ì„¤ì •
options = webdriver.ChromeOptions()
options.add_argument("--disable-gpu")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--headless=new")

# 2. ì„ì‹œ user-data-dir ìƒì„± (ì„¸ì…˜ ê²©ë¦¬)
temp_user_data_dir = tempfile.mkdtemp(prefix="selenium-profile-")
options.add_argument(f"--user-data-dir={temp_user_data_dir}")

# 3. ChromeDriver ì‹¤í–‰
service = Service("/usr/bin/chromedriver")
driver = webdriver.Chrome(service=service, options=options)

# 4. ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (ì´ë¯¸ì§€Â·ë§í¬ ì œê±°)
def extract_clean_text(element):
    for tag in element.find_elements(By.TAG_NAME, "img") + element.find_elements(By.TAG_NAME, "a"):
        driver.execute_script("arguments[0].remove();", tag)
    return element.text.strip()

# 5. ë³¸ë¬¸ ì´ë¯¸ì§€ ì—¬ë¶€ ê²€ì‚¬ (ì˜¤ì§ /groups/ ê²½ë¡œì˜ ì´ë¯¸ì§€ë§Œ)
def has_visible_content_images(element):
    imgs = element.find_elements(By.TAG_NAME, "img")
    for img in imgs:
        if not img.is_displayed():
            continue
        src = img.get_attribute("src") or ""
        if "groups/" in src:
            return True
    return False

# 6. ê²Œì‹œê¸€ ë§í¬ ìˆ˜ì§‘
def collect_thread_links(start_url, max_pages=3):
    links = []
    driver.get(start_url)
    time.sleep(3)
    for _ in range(max_pages):
        for a in driver.find_elements(By.CSS_SELECTOR, "a[href*='/g/ns-3-users/c/']"):
            href = a.get_attribute("href")
            if href and href not in links:
                links.append(href)
        try:
            nxt = driver.find_element(By.CSS_SELECTOR, "div[aria-label='ë‹¤ìŒ í˜ì´ì§€']")
            driver.execute_script("arguments[0].click()", nxt)
            time.sleep(2)
        except:
            break
    return links

# 7. ì§ˆë¬¸-ë‹µë³€ íŒŒì‹±
def parse_thread(url):
    driver.get(url)
    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_all_elements_located((By.CSS_SELECTOR, "section[data-author]"))
        )
        secs = driver.find_elements(By.CSS_SELECTOR, "section[data-author]")
        if len(secs) < 2:
            print("âŒ ë‹µë³€ ì—†ìŒ:", url)
            return None

        # ì§ˆë¬¸ ë³¸ë¬¸ë§Œ ì¶”ì¶œ & clean
        q_sec = secs[0]
        try:
            q_region = q_sec.find_element(By.CSS_SELECTOR, "div[role='region']")
            raw_q = q_region.text
        except:
            raw_q = q_sec.text
        question = re.sub(r"\s+", " ", raw_q).strip()

        # Tommaso ì„¹ì…˜ ì°¾ê¸°
        t_sec = next((s for s in secs[1:]
                      if s.get_attribute("data-author") == "Tommaso Pecorella"), None)
        if not t_sec:
            print("âŒ Tommaso ë‹µë³€ ì—†ìŒ:", url)
            return None

        # ë³¸ë¬¸ ì´ë¯¸ì§€ í¬í•¨ ì—¬ë¶€
        if has_visible_content_images(q_sec):
            print("ğŸ–¼ï¸ ì§ˆë¬¸ ë³¸ë¬¸ì— ì´ë¯¸ì§€ í¬í•¨ â†’ ì œì™¸:", url)
            return None
        if has_visible_content_images(t_sec):
            print("ğŸ–¼ï¸ Tommaso ë‹µë³€ ë³¸ë¬¸ì— ì´ë¯¸ì§€ í¬í•¨ â†’ ì œì™¸:", url)
            return None

        # ë‹µë³€ ë³¸ë¬¸ë§Œ ì¶”ì¶œ & clean
        try:
            a_region = t_sec.find_element(By.CSS_SELECTOR, "div[role='region']")
            raw_a = a_region.text
        except:
            raw_a = t_sec.text
        answer = re.sub(r"\s+", " ", raw_a).strip()

        if not answer:
            print("âš ï¸ ë‹µë³€ ë¹„ì–´ ìˆìŒ:", url)
            return None

        print("âœ… Tommaso ë‹µë³€ ìˆ˜ì§‘:", url)
        return {
            "url": url,
            "question": question,
            "answer": answer
        }

    except Exception as e:
        print(f"âš ï¸ í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨ ({url}): {e}")
    return None

# 8. ë©”ì¸ ì‹¤í–‰ ë¡œì§
if __name__ == "__main__":
    base_url = "https://groups.google.com/g/ns-3-users"
    threads = collect_thread_links(base_url, max_pages=3)

    results = []
    seen = set()
    for link in threads:
        if link in seen:
            continue
        seen.add(link)

        print(f"\nğŸ” í¬ë¡¤ë§ ì¤‘: {link}")
        qa = parse_thread(link)
        if qa:
            results.append(qa)

    with open("tommaso_qa.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“¦ ì €ì¥ ì™„ë£Œ: {len(results)}ê°œ ìˆ˜ì§‘ë¨")

    driver.quit()
    shutil.rmtree(temp_user_data_dir, ignore_errors=True)
